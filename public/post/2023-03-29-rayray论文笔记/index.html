<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>[Ray]Ray论文笔记 - fzhiy&#39;s blog</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="fzhiy" /><meta name="description" content="Ray论文 Real-Time Machine Learning: The Missing Pieces Ray: A Distributed Framework for Emerging AI Applications [Ray]Ray: A Distributed Framework for Emerging AI Applications 与supervised learning不同的是，training和serving可以由" /><meta name="keywords" content="ray" />






<meta name="generator" content="Hugo 0.88.1 with theme even" />


<link rel="canonical" href="https://blog.fzhiy.net/post/2023-03-29-rayray%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="[Ray]Ray论文笔记" />
<meta property="og:description" content="Ray论文 Real-Time Machine Learning: The Missing Pieces Ray: A Distributed Framework for Emerging AI Applications [Ray]Ray: A Distributed Framework for Emerging AI Applications 与supervised learning不同的是，training和serving可以由" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://blog.fzhiy.net/post/2023-03-29-rayray%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2023-03-29T15:51:32+08:00" />
<meta property="article:modified_time" content="2023-03-29T15:51:32+08:00" />

<meta itemprop="name" content="[Ray]Ray论文笔记">
<meta itemprop="description" content="Ray论文 Real-Time Machine Learning: The Missing Pieces Ray: A Distributed Framework for Emerging AI Applications [Ray]Ray: A Distributed Framework for Emerging AI Applications 与supervised learning不同的是，training和serving可以由"><meta itemprop="datePublished" content="2023-03-29T15:51:32+08:00" />
<meta itemprop="dateModified" content="2023-03-29T15:51:32+08:00" />
<meta itemprop="wordCount" content="6477">
<meta itemprop="keywords" content="ray," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="[Ray]Ray论文笔记"/>
<meta name="twitter:description" content="Ray论文 Real-Time Machine Learning: The Missing Pieces Ray: A Distributed Framework for Emerging AI Applications [Ray]Ray: A Distributed Framework for Emerging AI Applications 与supervised learning不同的是，training和serving可以由"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">fzhiy&#39;s blog</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">主页</li>
      </a><a href="https://fzhiy.net">
        <li class="mobile-menu-item">fzhiy的空间</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">归档</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">标签</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">分类</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">fzhiy&#39;s blog</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">主页</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="https://fzhiy.net">fzhiy的空间</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">归档</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">标签</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">分类</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">[Ray]Ray论文笔记</h1>

      <div class="post-meta">
        <span class="post-time"> 2023-03-29 </span>
        <div class="post-category">
            <a href="/categories/paper-notes/"> paper-notes </a>
            <a href="/categories/ray/"> ray </a>
            </div>
          <span class="more-meta"> 约 6477 字 </span>
          <span class="more-meta"> 预计阅读 13 分钟 </span>
        <span id="busuanzi_container_page_pv" class="more-meta"> <span id="busuanzi_value_page_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 次阅读 </span>
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#rayray-a-distributed-framework-for-emerging-ai-applications">[Ray]Ray: A Distributed Framework for Emerging AI Applications</a>
          <ul>
            <li><a href="#编程模型和计算模型">编程模型和计算模型</a></li>
            <li><a href="#架构">架构</a></li>
            <li><a href="#对象重建">对象重建</a></li>
            <li><a href="#相关工作">相关工作</a></li>
            <li><a href="#references">References</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <blockquote>
<p>Ray论文</p>
<ul>
<li><a href="https://arxiv.org/abs/1703.03924">Real-Time Machine Learning: The Missing Pieces</a></li>
<li><a href="https://arxiv.org/abs/1712.05889">Ray: A Distributed Framework for Emerging AI Applications</a></li>
</ul>
</blockquote>
<h2 id="rayray-a-distributed-framework-for-emerging-ai-applications">[Ray]Ray: A Distributed Framework for Emerging AI Applications</h2>
<p><img src="https://img.fzhiy.net/img/image-20230329135318199.png" alt="image-20230329135318199"></p>
<p><img src="https://img.fzhiy.net/img/image-20230329140956911.png" alt="image-20230329140956911"></p>
<p>与supervised learning不同的是，training和serving可以由不同的系统分别处理，而在<em>RL</em>中，所有的<code>training, serving, simulation</code>这三个workloads都紧密地耦合在一个应用程序中，它们之间有严格的延迟要求。 目前没有框架支持这样的耦合。</p>
<p>因此，框架需要满足以下要求：</p>
<ol>
<li><code>Fine-grained, heterogeneous computations.</code> 计算持续时间范围 从毫秒（如 taking an action）到小时量级（如 training a complex policy）。此外，训练经常要求异质的硬件（如 CPUs，GPUs或者TPUs）。</li>
<li><code>Flexible computation model.</code> RL应用要求 无状态stateless和有状态的stateful 计算。无状态计算可以在系统的任何节点上执行，这使得在需要时很容易实现负载平衡和将计算转移到数据上。因此，<u>无状态计算很适合细粒度的模拟和数据处理</u>，如从图像或视频中提取特征。相比之下，<u>有状态的计算很适合于实现参数服务器</u>，在GPU支持的数据上进行重复计算，或者运行第三方的 仿真器，这些仿真器不暴露它们的状态。</li>
<li><code>Dynamic execution.</code> RL应用的几个组成部分需要动态执行，因为计算完成的顺序并不总是事先知道的（如 仿真完成的顺序），而一个计算的结果可以决定未来的计算（如 仿真的结果决定我们是否需要进行更多的模拟）。</li>
</ol>
<p>需要一个框架：</p>
<ul>
<li>支持异构的、动态的计算图；</li>
<li>每秒处理百万级任务数且只有毫秒级的延迟</li>
<li>批量同步并行系统<code>bulk-synchronous parallel system</code>。</li>
</ul>
<h3 id="编程模型和计算模型">编程模型和计算模型</h3>
<p>Ray提供了<code>actor 和 task-parallel</code>两重编程抽象。不像CIEL，只提供任务并行抽象，或者Orleans和Akka，只提供了actor抽象。</p>
<h4 id="编程模型">编程模型</h4>
<ul>
<li>
<p><code>Tasks</code>。一个任务task表示在无状态工作器上执行一个远程函数。当一个带有<code>@remote</code>注解的remote函数被调用，会立即返回一个<code>future</code>对象，然后调用<code>ray.get()</code>即可得到结果。</p>
<blockquote>
<p>比如说</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">import time
import ray

ray.init()

@ray.remote
def f():
    time.sleep(1)
    return 1

# Execute f in parallel.
object_ids = [f.remote() for i in range(4)]
results = ray.get(object_ids)
</code></pre></td></tr></table>
</div>
</div><p><code>f.remote()</code>调用运行时，将返回一个<code>future</code>对象，存储在<code>object_ids</code>中，调用<code>ray.get(object_ids)</code>可以得到返回值的列表。</p>
</blockquote>
<p>remote函数操作的数据是不可变的对象，remote函数是无状态，无副作用的，使得幂等性得以保证，从而简化了容错的处理。</p>
</li>
<li>
<p><code>Actors</code>。一个角色actor代表一个<strong>有状态的stateful计算</strong>。每个角色都暴露了可以被远程调用的方法，并被连续执行。一个<u>方法的执行</u>类似于一个<em>任务task</em>，因为它是远程执行并返回一个未来，但不同的是它是在一个<strong>有状态的worker</strong>上执行的。一个actor的<code>句柄handle</code>可以传递给其他角色或任务，使他们有可能调用该角色的方法。</p>
<p><img src="https://img.fzhiy.net/img/image-20230329163905360.png" alt="image-20230329163905360"></p>
<center>Tasks vs. actors tradeoffs</center>
<p><img src="https://img.fzhiy.net/img/image-20230329163811643.png" alt="image-20230329163811643"></p>
<center>Ray API</center>
<p>为了满足上一节提到的<code>heterogeneity</code>和<code>flexibility</code>需求，通过三种方程增强API的功能：</p>
<ol>
<li>处理不同时长的并发任务，采用<code>ray.wait()</code>，等待<em>前k个</em>可用结果，而不是像<code>ray.get()</code>等待<em>所有</em>结果；</li>
<li>处理资源异质的任务，让开发者指定资源需求以使Ray scheduler能够高效管理资源；</li>
<li>提高灵活性<code>flexibility</code>，允许<code>nested remote functions</code>，也就是remote functions能够调用其他remote functions。这也是实现高可用的重要部分，因为能够让多个进程以分布式方式调用remote functions。</li>
</ol>
</li>
</ul>
<h4 id="计算模型">计算模型</h4>
<p>一个计算图中有两类节点nodes：（1）data objects，（2）remote function invocations or tasks。</p>
<p>两类边edges：（1）data edges；（2）control edges。前者捕捉<em>data objects与tasks之间的依赖</em>（如 data object $D$是任务$T$的输出，就添加一条<em>从$T$到$D$的data edge</em>）。后者捕捉<em>嵌套remote functions得到的计算依赖</em>（如任务$T_1$调用任务$T_2$，就添加一条<em>从$T_1$到$T_2$的control edges</em>）。</p>
<p>为了捕获同一actor的后续方法调用中的状态依赖性，添加了第三种类型的边：<code>stateful edge</code>。（如 在相同actor上，方法$M_j$正好在方法$M_i$之后调用，就添加一条从$M_i$到$M_j$的stateful edge）。</p>
<p>有状态边有两种好处，</p>
<ul>
<li>一是使得我们可以把actor嵌入到无状态的任务图中，因为actor维护着自己的一个调用链和状态。</li>
<li>二是，有状态边可以用来维护世系(lineage)信息，世系可以帮助Ray重建数据对象，包括remote function创建的或是actor method创建的。</li>
</ul>
<p><img src="https://img.fzhiy.net/img/image-20230329135402069.png" alt="image-20230329135402069"></p>
<h3 id="架构">架构</h3>
<p>Ray架构由（1）实现API的<strong>应用层</strong>，（2）提供高可扩展性和容错性的<strong>系统层</strong> 组成。</p>
<p><img src="https://img.fzhiy.net/img/image-20230329144117190.png" alt="image-20230329144117190"></p>
<h4 id="应用层">应用层</h4>
<p>应用层由三类进程process组成：</p>
<ol>
<li><code>Driver</code>：执行用户程序的进程；</li>
<li><code>Worker</code>: 被driver或另一个worker调用的 执行任务(remote functions)的无状态进程。workers被自动启动，并由系统层分配任务。当一个remote function被声明时，该函数会自动发布给所有workers。worker以串行方式执行任务，在不同的任务中不保留本地状态。</li>
<li><code>Actor</code>: 一个有状态的进程，当被调用时，只执行它所暴露的方法。与 Worker 不同，Actor 是由 Worker 或 Driver显示实例化的。与Workers一样，Actor也是以串行方式执行方法，只是每个方法都依赖于前一个方法的执行所产生的状态。</li>
</ol>
<h4 id="系统层">系统层</h4>
<p>系统层由三个主要部分组成：（1）<code>global control store</code>；（2）<code>distributed scheduler</code>；（3）<code>distributed object store</code>。所有成分都是横向可扩展的并具有容错性。</p>
<h5 id="global-control-store-gcs">Global Control Store (GCS)</h5>
<blockquote>
<p>全局控制状态（GCS）是一个中心化的存储，使用Redis实现，负责存储task描述，remote方法代码，计算图，对象的位置，以及每个调度事件。
将所用控制状态集中存储，有这么几个好处：
1）使得集群中其他组件、节点可以无状态。这样的话可以大大提升水平扩展的能力。
2）简化了容错。
3）方便对程序debug，profile。</p>
<p>当然，集中式存储带来的隐忧就是瓶颈问题，基于Redis，可以做分片(sharding)来缓解单点瓶颈。并且为每个分片提供热副本(hot replica)【是什么？】来容错。
鉴于在Ray中，每个task, object, method等都有一个唯一的伪随机ID与其一一对应，使得分片间能够更好地负载均衡。</p>
</blockquote>
<h5 id="bottom-up-distributed-scheduler">Bottom-Up Distributed Scheduler</h5>
<p><img src="https://img.fzhiy.net/img/image-20230329150629299.png" alt="image-20230329150629299"></p>
<blockquote>
<p>分布式自底向上调度器（distributed bottom-up scheduler），负责任务的调度。Ray启动时，会启动一个全局的调度器global scheduler，实现上是一个redis server，会在每个从节点上启动一个local scheduler，每个节点上提交的task率先提交给各自的local scheduler进行调度，如果local scheduler调度不了，则上推给global scheduler，进行集群全局范围的调度。
Ray这样设计的目标是调度可扩展性以及快速，低延迟的调度。这样设计带来的好处就是Ray调度任务非常之快。</p>
<p>那么Ray这样设计的灵感来自于哪里呢？</p>
<p>通常的分布式集群计算框架实现的都是中心化，集中式的调度，如Hadoop, Spark, CIEL, Dryad等。这种方式<u>虽然简化了设计，但是扩展性不好</u>。</p>
<p>提升调度扩展性有几种方式：
1）批量调度。调度器批量提交任务给worker节点，以摊销提交任务带来的固定开销。Drizzle框架实现的就是这种。
2）层次调度。即全局调度器(global scheduler)将任务图划分到各个节点的本地调度器(local scheduler)。Canary框架实现了这种调度。
3）并行调度。多个全局调度器同时进行任务调度。这是Sparrow框架所做的。</p>
<p>但是他们都有各自的缺陷。
批量调度仍然需要一个全局调度器来处理所有任务。
层次调度假设任务图是已知的，即假设任务图是静态的。
并行调度假设每个全局调度器调度独立的作业。</p>
<p>Ray希望做到的是高可扩展性，处理动态任务图，并且可能处理来自同一个作业的任务。</p>
<p><strong>Ray的自底向上调度器类似层次调度</strong>，不同的是，<strong>一个节点生成的task首先提交到各自的local scheduler，由local scheduler进行调度</strong>。除非本地节点过载了，或者本地节点不能满足task的资源需求，或者task的输入不在本地节点等因素出现，否则本地节点可以完成调度。</p>
<p>其实最后一条，task的输入不在本地，仍有方式在本地调度，因为object store可以实现快速的数据对象转运。</p>
<p>看到这里，读者可能想问，Ray的local scheduler是怎样判断是否该调度到本地节点还是上推到global scheduler呢？</p>
<p>Ray是这样处理的，local scheduler会维护一个任务队列（task queue），每次调度任务时它会检查<strong>当前任务队列的长度</strong>，如果超过一定的<strong>阈值</strong>，那么认为本机过载了，不在调度当前任务而是将其转给上层全局调度器。</p>
<ul>
<li>这个阈值为0，则调度为集中式的调度，全靠global scheduler负责。</li>
<li>这个阈值为无穷大，则调度为去中心化的分布式调度，所有任务都有本地节点负责。</li>
</ul>
<p>在框架设计上，local scheduler每隔一段时间会发送心跳包给<strong>GCS</strong>，注意不是直接发送给global scheduler，心跳包中会包含local scheduler的负载信息，GCS收到以后记录此信息，转发给global scheduler。
当收到local scheduler转发来的任务时，global scheduler使用最新的负载信息，以及人物的输入数据对象的位置和大小，来决定将task分发到哪个节点去运行。</p>
<p>如果global scheduler成为了瓶颈，那么采用多个副本，local scheduler随机选择一个global scheduler去转发任务。</p>
</blockquote>
<h5 id="in-memory-distributed-object-store">In-Memory Distributed Object Store</h5>
<blockquote>
<p>remote函数（task）的输入和输出数据都存储在Distributed Object Store中。
调用一个函数时，其输入首先被隐式执行<code>ray.put</code>，存储object store中，其输出也会被放入object store中，函数返回一个object id为该输出数据的唯一id，调用<code>ray.get(object_id)</code>才可获得任务返回的实际数据。</p>
<p>同一个节点上使用**共享内存(shared memory)<strong>来实现object store，这使得两个不同的worker进程或者driver和worker之间能够</strong>零拷贝(zero copy)**地访问共同的数据。具体实现<u>采用了Apache Arrow中的plasma store</u>。<a href="http://arrow.apache.org/">Apache Arrow</a>是一种跨平台的内存数据交换格式。可参看介绍，等。</p>
<p>如果一个task，其输入不在本地，那么object store会把数据从所在地拷贝到本地，这样可以避免热数据带来的瓶颈，同时可以加快程序执行速度，因为直接在本地内存中操作。当然，数据的传送开销也是免不了的。这也将提升计算受限工作流的吞吐量，计算受限是许多AI应用共有的特征。</p>
<p>为了简化系统设计，简化容错，Ray像其它内存计算系统如Spark, Dryad一样，<strong>其操作的数据是不可变的(immutable)</strong>，即<strong>存储在object store中的数据不能改变</strong>，如RDD一般。</p>
<p>Ray同时也不支持分布式对象，如分布式大矩阵，当然可以通过在应用层自行实现（通过一系列的futures）。</p>
</blockquote>
<h5 id="implementation">Implementation</h5>
<p><a href="https://github.com/ray-project/ray">https://github.com/ray-project/ray</a></p>
<h4 id="end-to-end-exampleab-return-c">end-to-end example（a+b, return c）</h4>
<p>图(a)中，节点1(N1)向GCS注册了函数<code>add()</code>，N1调用，在N2执行。</p>
<p><img src="https://img.fzhiy.net/img/image-20230329153550816.png" alt="image-20230329153550816"></p>
<p>图(b)中，N1用<code>ray.get()</code>得到了<code>add()</code>的结果。c的Object Table在第四步被创建，并在步骤6中（被复制到N1后）被更新。</p>
<p><img src="https://img.fzhiy.net/img/image-20230329153608901.png" alt="image-20230329153608901"></p>
<blockquote>
<p>原文参见：http://whatbeg.com/2018/03/15/ray-paper.html</p>
<h3 id="对象重建">对象重建</h3>
<p>像Spark，CIEL一样，Ray根据世系来重建对象。除此之外，Ray还支持有状态操作算子(Actor)的重建。</p>
<p>要注意的是，如果世系中包含有状态边，则可能涉及到Actor的重新初始化，并且可能涉及到很长一条世系链的重放。对于某些应用，Ray为了减少Actor的重建时间，加入了checkpoint机制，从checkpoint进行恢复。</p>
<p>为了保证低延迟，如果plasma store满了以后，会通过LRU机制剔除陈旧的对象到磁盘。【到磁盘哪里？】
在Ray中，plasma store即object store挂载在Linux属于tmpfs文件系统的<code>/dev/shm</code>目录上，该目录不在磁盘上，而在内存里。已经存入<code>/dev/shm</code>中的对象不能被其他应用程序使用，但是<code>/dev/shm</code>没被使用的部分可被其他应用程序使用。
<code>/dev/shm</code>区域的大小一般是总内存的1/2。即如果你的机器是64G内存，那么此区域只有32G可用，Ray会再保留一点余量，大概用于object store的空间只有26-27GB左右，也就是说，如果Ray处理的数据过大，大到object store都装不下或者在运行时需要频繁evict甚至evict掉其他必要数据的时候，往往程序就会崩溃。</p>
</blockquote>
<blockquote>
<h3 id="相关工作">相关工作</h3>
<p>下表对相关工作与Ray的相似点与不同点做一总结。</p>
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th style="text-align:left">比较的系统框架</th>
<th style="text-align:left">相似点</th>
<th style="text-align:left">不同点</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">动态任务图</td>
<td style="text-align:left">CIEL</td>
<td style="text-align:left">动态任务图机制，futures抽象，通过世系容错</td>
<td style="text-align:left">Ray还提供Actor抽象，并实现了全局控制面板，自底向上调度器和采用了内存对象存储而不是文件存储，扩展到Python语言</td>
</tr>
<tr>
<td style="text-align:left">Dask</td>
<td style="text-align:left">支持动态任务图，wait原语，futures抽象，Python语言</td>
<td style="text-align:left">Dask是中心化调度方式，不提供actor抽象，不提供容错</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">数据流系统</td>
<td style="text-align:left">Hadoop/Spark</td>
<td style="text-align:left"></td>
<td style="text-align:left">Hadoop/Spark计算模型更加限定，实现了BSP执行模型，假设同一阶段的task执行同样的计算，并有着相似的执行时间。Ray还提供Actor抽象，并实现了全局控制面板和调度器。</td>
</tr>
<tr>
<td style="text-align:left">Dryad</td>
<td style="text-align:left"></td>
<td style="text-align:left">Dryad放松了Spark的假设，但是也没有实现动态计算图。Ray还提供Actor抽象，并实现了全局控制面板和调度器。</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">Naiad</td>
<td style="text-align:left">对于一些工作流提升了可扩展性。</td>
<td style="text-align:left">只支持静态计算图。</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">Actor系统</td>
<td style="text-align:left">Orleans</td>
<td style="text-align:left">提供虚拟actor-based抽象。</td>
<td style="text-align:left">Orleans可以使actor的多个实例同时运行。需要显式checkpoint，提供at-least-once语义。而Ray提供exactly-once语义。[注]</td>
</tr>
<tr>
<td style="text-align:left">Erlang</td>
<td style="text-align:left">Actor抽象。</td>
<td style="text-align:left">需显式处理容错。Erlang的全局状态存储不适合共享大对象。</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">C++ Actor Framework</td>
<td style="text-align:left">Actor抽象。</td>
<td style="text-align:left">需显式处理容错。不支持数据共享。</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">全局控制状态和调度</td>
<td style="text-align:left">SDN</td>
<td style="text-align:left">全局控制状态</td>
<td style="text-align:left">Ray解耦了状态信息存储和逻辑实现（调度器），存储与计算可以独立扩展</td>
</tr>
<tr>
<td style="text-align:left">Distributed File System，如GFS</td>
<td style="text-align:left">全局控制状态</td>
<td style="text-align:left">Ray解耦了状态信息存储和逻辑实现（调度器），存储与计算可以独立扩展</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">Distributed Frameworks (如MapReduce, BOOM)</td>
<td style="text-align:left">全局控制状态</td>
<td style="text-align:left">与BOOM相比，Ray解耦了状态信息存储和逻辑实现（调度器），存储与计算可以独立扩展</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">Resource Management (Omega)</td>
<td style="text-align:left">全局共享状态</td>
<td style="text-align:left">Ray增加了两层调度器来均衡负载，面向毫秒级别的任务调度</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">Sparrow</td>
<td style="text-align:left">去中心化调度</td>
<td style="text-align:left">各调度器自行其是，独立决策</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">Mesos</td>
<td style="text-align:left">两级层次调度</td>
<td style="text-align:left">顶层调度器可能成为瓶颈</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">Canary</td>
<td style="text-align:left">去中心化调度</td>
<td style="text-align:left">Canary每个调度器负责计算图的一部分，但不支持动态计算图</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">机器学习框架</td>
<td style="text-align:left">Tensorflow</td>
<td style="text-align:left"></td>
<td style="text-align:left">面向深度学习，对CPU、GPU资源利用很好，不支持更通用的计算工作流，Tensorflow Fold提供对动态计算图的一些支持，但仍无法全部支持执行时对任务执行进度，任务完成时间和错误的响应而编辑DAG图。支持底层消息传输和同步原语，但是过于底层使得用起来有点像MPI。</td>
</tr>
<tr>
<td style="text-align:left">MXNet</td>
<td style="text-align:left"></td>
<td style="text-align:left">同Tensorflow</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">OpenMPI</td>
<td style="text-align:left">高性能</td>
<td style="text-align:left">很难编程，需要显式处理异构和动态任务图，需要程序员显式处理容错</td>
<td style="text-align:left"></td>
</tr>
</tbody>
</table>
<p>[注] 实时计算/流式计算的三种语义：
At-most-once：每条记录最多只能被处理一次
At-least-once：每条记录最少要被处理一次
Exactly-once：每条记录有且仅被处理一次</p>
</blockquote>
<h3 id="references">References</h3>
<ul>
<li><a href="https://arxiv.org/abs/1712.05889">Ray: A Distributed Framework for Emerging AI Applications</a></li>
<li><a href="http://whatbeg.com/2018/03/15/ray-paper.html">Ray 论文解读</a></li>
<li><a href="https://matt33.com/2019/10/19/paper-ray1/">https://matt33.com/2019/10/19/paper-ray1/</a></li>
<li><a href="https://www.cnblogs.com/fanzhidongyzby/p/7901139.html">https://www.cnblogs.com/fanzhidongyzby/p/7901139.html</a></li>
</ul>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content">fzhiy</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        2023-03-29
        
    </span>
  </p>
  
  
</div>
<div class="post-reward">
  <input type="checkbox" name="reward" id="reward" hidden />
  <label class="reward-button" for="reward">赞赏支持</label>
  <div class="qr-code">
    
    <label class="qr-code-image" for="reward">
        <img class="image" src="https://img.fzhiy.net/img/20200812154839.png">
        <span>微信打赏</span>
      </label>
    <label class="qr-code-image" for="reward">
        <img class="image" src="https://img.fzhiy.net/img/20200812154858.png">
        <span>支付宝打赏</span>
      </label>
  </div>
</div><footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/ray/">ray</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/2023-04-05-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">设计模式</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/2022-09-03-%E5%9F%BA%E4%BA%8Eelk&#43;kafka%E6%90%AD%E5%BB%BA%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%88%9D%E6%AD%A5%E5%AE%9E%E7%8E%B0/">
            <span class="next-text nav-default">基于ELK&#43;Kafka搭建日志平台架构设计与初步实现</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  
    <script src="https://utteranc.es/client.js"
            repo="fzhiy/blog"
            issue-term="pathname"
            theme="github-light"
            crossorigin="anonymous"
            async>
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://github.com/utterance">comments powered by utterances.</a></noscript>

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:fzhiy270@163.com" class="iconfont icon-email" title="email"></a>
      <a href="https://github.com/fzhiy" class="iconfont icon-github" title="github"></a>
      <a href="https://blog.csdn.net/feng_zhiyu" class="iconfont icon-csdn" title="csdn"></a>
      <a href="https://www.zhihu.com/people/ni-feng-88-10" class="iconfont icon-zhihu" title="zhihu"></a>
  <a href="https://blog.fzhiy.net/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  <div class="busuanzi-footer">
    <span id="busuanzi_container_site_pv"> 本站总访问量 <span id="busuanzi_value_site_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 次 </span>
      <span class="division">|</span>
    <span id="busuanzi_container_site_uv"> 本站总访客数 <span id="busuanzi_value_site_uv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 人 </span>
  </div>

  <span class="copyright-year">
    &copy; 
    2020 - 
    2023<span class="heart"><i class="iconfont icon-heart"></i></span><span>fzhiy</span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/timeago.js@3.0.2/dist/timeago.min.js" integrity="sha256-jwCP0NAdCBloaIWTWHmW4i3snUNMHUNO+jr9rYd2iOI=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/timeago.js@3.0.2/dist/timeago.locales.min.js" integrity="sha256-ZwofwC1Lf/faQCzN7nZtfijVV6hSwxjQMwXL4gn9qU8=" crossorigin="anonymous"></script>
  <script><!-- NOTE: timeago.js uses the language code format like "zh_CN" (underscore and case sensitive) -->
    var languageCode = "en".replace(/-/g, '_').replace(/_(.*)/, function ($0, $1) {return $0.replace($1, $1.toUpperCase());});
    timeago().render(document.querySelectorAll('.timeago'), languageCode);
    timeago.cancel();  
  </script>



<script type="text/javascript" src="/js/main.min.c99b103c33d1539acf3025e1913697534542c4a5aa5af0ccc20475ed2863603b.js"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        tags: 'ams',
        }
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js" integrity="sha256-HGLuEfFcsUJGhvB8cQ8nr0gai9EucOOaIxFw7qxmd+w=" crossorigin="anonymous"></script>

<script id="baidu_analytics">
  var _hmt = _hmt || [];
  (function() {
    if (window.location.hostname === 'localhost') return;
    var hm = document.createElement("script"); hm.async = true;
    hm.src = "https://hm.baidu.com/hm.js?e4ff802fe8f2731918ababdb4ccf87bc";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
  })();
</script>

<script id="baidu_push">
  (function(){
    if (window.location.hostname === 'localhost') return;
    var bp = document.createElement('script'); bp.async = true;
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
      bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
      bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
  })();
</script>




</body>
</html>
